# -*- coding: utf-8 -*-
"""Behavioural_Cloning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ELzhGIw6pJtwUl2eL10_yICX-egqOlW5
"""

!pip3 install imgaug
!pip install scikit-image==0.14.2
import numpy as np
import matplotlib.pyplot as plt
import keras
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.utils.np_utils import to_categorical
from keras.layers import Dropout, Flatten, Convolution2D, MaxPooling2D
from imgaug import augmenters as iaa #imgaug has a lot more augmentation options then Keras Image Prepocessing
import matplotlib.image as mpimg
import pickle
import random
import pandas as pd
import cv2
import ntpath #to split path as we only want the last part
import os #imported to join driving_log and the directory
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split

#!git clone https://github.com/Cedmalloc/Track_Data.git
!git clone https://github.com/rslim087a/track
!ls track

directory = 'track'  #equal to git repository name
columns = ['center','left','right','steering','throttle','reverse','speed']  #columns used below
data = pd.read_csv(os.path.join(directory, 'driving_log.csv'),names = columns)
pd.set_option('display.max_colwidth',-1) #allows us to see all columns
data.head()

#make sure to only use last part of path :
def path_end(path):
  beginning,end = ntpath.split(path)
  return end #only end is needed 

data['center'] = data['center'].apply(path_end) #applies function to all elements in center column
data['left'] = data['left'].apply(path_end) #applies function to all elements in center column
data['right'] = data['right'].apply(path_end) #applies function to all elements in center column

#data['steering'].hist()

num_of_bins = 25 #has to be odd to get middle value 
threshold = 400; 
hist, bins = np.histogram(data['steering'],num_of_bins)
#center values around 0 :
center = (bins[:-1] + bins[1:]) *0.5 #elementswise addition, appr. doubles so *0.5
plt.bar(center, hist, width = 0.05)
plt.plot([np.min(data['steering']), np.max(data['steering'])],[threshold, threshold])
#print(bins)

#as we can see it's almost symmetric due to turning around and driving the other way as well if we made a mistake generating our data we would be able to see that right here:
#model is fairly biased towards driving straight which can be changed via a threshold 
#bar plot would show a bias towards a certain steering angle
#an idea would be to only go one way and then artifically averaging the data out, in a way adding the right turn data to left turn and the other way around to get better generalization
remove = []
for j in range(num_of_bins):
  steer = []
  for i in range(len(data['steering'])) :
    if( data['steering'][i] >= bins[j] and data['steering'][i] <= bins[j+1]) :  #if steering angle is in between two bins, it belongs to current bin in iteration
      steer.append(i)  #add steering angle to list
      
      
  steer = shuffle(steer)  #shuffle is important to not loose parts of the track
  remove.extend(steer[threshold:])  #extend adds elements on to a list
      
data.drop(data.index[remove],inplace = True) #elements over threshold are dropped (if we have 700 : 700 - threshold are dropped)

hist, bins = np.histogram(data['steering'],num_of_bins)
#print(hist[0]) using hist and bin we coul create a perfect data set, due to the fact that the frame rate was very low we might need to come back and change that here
#hist[24] = 50
plt.bar(center, hist, width = 0.05)
plt.plot([np.min(data['steering']), np.max(data['steering'])],[threshold, threshold])

def load_image_data(dr, df):
  im_path = []
  steering = []
  for i in range(len(data)):   #iterate through data
    ind_data = data.iloc[i]
    center, left, right = ind_data[0], ind_data[1], ind_data[2]  
    #center image
    im_path.append(os.path.join(dr, center.strip()))   #add center data, strip erases spaces added just in case
    steering.append(float(ind_data[3]))       
    # left image
    im_path.append(os.path.join(dr,left.strip()))  # os.path.join : Join one or more path components intelligently
    steering.append(float(ind_data[3])+0.15)
    # right image 
    im_path.append(os.path.join(dr,right.strip()))
    steering.append(float(ind_data[3])-0.15)
    #convert to array
  im_paths = np.asarray(im_path)
  steerings = np.asarray(steering)
  return im_paths, steerings
 
im_paths, steerings = load_image_data(directory + '/IMG', data)
x_train, x_val, y_train, y_val = train_test_split(im_paths, steerings, test_size=0.2, random_state=6)
print('Training Samples: {}\nValid Samples: {}'.format(len(x_train), len(x_val)))
fig, axes = plt.subplots(1, 2, figsize=(12, 4))
axes[0].hist(y_train, bins=num_of_bins, width=0.05, color='blue')
axes[0].set_title('Training set')
axes[1].hist(y_val, bins=num_of_bins, width=0.05, color='red')
axes[1].set_title('Validation set')

def zoom(image):
  zoom = iaa.Affine(scale = (1,1.3))  #tuple for zoom (start,end) 1 = no zoom
  image = zoom.augment_image(image)
  return image

def pan(image):
  pan = iaa.Affine(translate_percent = {'x' : (-0.1,0.1),'y' : (-0.1,0.1)})  #percentages
  #Affine :
  #preserves points, straight lines and planes 
  #sets of parallel lines remain parallel after an affine transformation
  image = pan.augment_image(image)
  return image

#brightness
def bright(image):
  brightness = iaa.Multiply((0.2,1.2))  #darker images are better from experience
  image = brightness.augment_image(image)
  return image

#flip images
def im_flip(image,steering_angle):
  image = cv2.flip(image, 1) #1: vertical flip, 0:horizontal, -1 : both
  #steering_angle needs to be flipped too
  steering_angle = -steering_angle 
  return image, steering_angle

#randomize occurence of augmentations => improved generalization
def rand_augment(image, steering_angle):
  image = mpimg.imread(image)
  if np.random.rand() < 0.5 : #random between 0 and 1 => executed 50 % of the time
   image = pan(image)
  if np.random.rand() < 0.5 : #random between 0 and 1 => executed 50 % of the time
   image = zoom(image)
  if np.random.rand() < 0.5 : #random between 0 and 1 => executed 50 % of the time
   image, steering_angle = im_flip(image, steering_angle)
  if np.random.rand() < 0.5 : #random between 0 and 1 => executed 50 % of the time
   image = bright(image)
  return image, steering_angle

fig, axs = plt.subplots(10 , 2 , figsize = (15,50) )
fig.tight_layout()
for i in range(10):
  num = random.randint(0,len(im_paths)-1)
  random_image = im_paths[num]         #random image
  random_steering = steerings[num]     #respective steering angle 
  
  original = mpimg.imread(random_image)       
  augmented , steering_angle = rand_augment(random_image, random_steering)
  
  axs[i][0].imshow(original)
#axs[0].set_title('Original')
  axs[i][0].set_title('Original ' + 'Steering Angle : ' + str(steering_angle))
  axs[i][1].imshow(augmented)
  axs[i][1].set_title('Augmented ' + 'Steering Angle : ' + str(steering_angle))

#image preprocessing
def pre_pro(img):
  #crop image
  img = img[60:135,:,:]  #crop trees and scenery (irrelevant in terms of just predicting the steering angle)
  #132 is making sure to cut out the hood
  #relying on Nvidia Model : yuv color space required
  img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)   #there's a difference between cv2.COLOR_RGB2YUV and cv2.COLOR_BGR2YUV
  #Gaussian blur to reduce image noise
  img = cv2.GaussianBlur(img,  (3, 3), 0)
  #image = cv2.resize(image, (image.shape[1],old_size))
  img = cv2.resize(img, (200, 66))
  #normalization
  img = img/255
  return img


image = im_paths[100]

natural_im = mpimg.imread(image)
preprocessed_image = pre_pro(natural_im)
fig, axs = plt.subplots(1,2,figsize = (15,10))
axs[0].imshow(natural_im)
axs[0].set_title('Not preprocessed')
axs[1].imshow(preprocessed_image)
axs[1].set_title('Preprocessed image')

def batch_generator(im_paths, steer_angle , batch_s , istraining): #istraining is set to true when training data is passed in , 0 for validation set


  while True:
    im_batch = []
    steering_batch = []
   
    for i in range(batch_s):
        rand_index =  random.randint(0, len(im_paths) - 1)
        if istraining:
            image , steering = rand_augment(im_paths[rand_index],steer_angle[rand_index])  #if training we augment
        else :     #if not training we keep the original 
            image, steering = mpimg.imread(im_paths[rand_index]), steer_angle[rand_index]
  
  #then we pre process
        image = pre_pro(image)
  #add to batches
        im_batch.append(image)
        steering_batch.append(steering)
    yield(np.asarray(im_batch),np.asarray(steering_batch))

#PREPROCESSING NOW HANDLED IN BATCH_GENERATOR FUNCTION
#preprocess all the images
#x_train = np.array(list(map(pre_pro, x_train)))
#x_val = np.array(list(map(pre_pro, x_val)))
#print(x_train.shape)

x_train_gen, y_train_gen = next(batch_generator(x_train, y_train, 1, 1))
x_valid_gen, y_valid_gen = next(batch_generator(x_val, y_val, 1, 0))
 
fig, axs = plt.subplots(1, 2, figsize=(15, 10))
fig.tight_layout()
 
axs[0].imshow(x_train_gen[0])
axs[0].set_title('Training Image')
 
axs[1].imshow(x_valid_gen[0])
axs[1].set_title('Validation Image')

def Nvidia_Model():
  #according to end-to-end deep learning for self driving cars, Dropout layers are added to prevent overfitting
  model = Sequential()
  model.add(Convolution2D(24,5,5 , subsample = (2,2), input_shape= (66,200,3),  activation = 'elu'))
  model.add(Convolution2D(36,5,5 , subsample = (2,2), activation = 'elu'))   #important to use elu here
  model.add(Convolution2D(48,3,3 , subsample = (2,2), activation = 'elu'))  
  model.add(Convolution2D(64,3,3 , activation = 'elu'))  #subsample removed as size is already reduced to 5x22
  model.add(Convolution2D(64,3,3 , activation = 'elu')) 
  #model.add(Dropout(0.5))
  model.add(Flatten())
  #FC Layer
 #model.add(Dense(1164), activation = 'relu')
 # model.add(Dropout(0.5))
  model.add(Dense((100) , activation = 'elu'))
  #model.add(Dropout(0.5))
  model.add(Dense((50), activation = 'elu'))
  model.add(Dense((10), activation = 'elu'))
  #model.add(Dropout(0.5))
  model.add(Dense((1)))
  
  optimizer = Adam(lr=1e-4)
  model.compile(loss='mse', optimizer=optimizer)
  return model

  #Dropout layers were removed as overfitting is less of an issue with 30000 generated images per epoch

model = Nvidia_Model()
print(model.summary())
history = model.fit_generator(batch_generator(x_train, y_train, 100, 1),
                                  steps_per_epoch=300, 
                                  epochs=10,   #less epochs needed now due to more data (30 epochs before)
                                  validation_data=batch_generator(x_val, y_val, 100, 0),
                                  validation_steps=200,
                                  verbose=1,
                                  shuffle = 1)

plt.plot(history.history['loss'],label = 'Training Loss')
plt.plot(history.history['val_loss'],label = 'Validation Loss')
plt.legend()
plt.title('Loss')
plt.xlabel('Epochs')

model.save('model.h5')
from google.colab import files
files.download('model.h5')
